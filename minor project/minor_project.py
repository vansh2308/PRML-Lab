# -*- coding: utf-8 -*-
"""Minor Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NYuWmSMJNJ6oFWcZkJn4TMYx1EQrZ4Z_

# _PRML Minor Project_
### _Online Retail Clustering_
Vansh Agarwal B21AI042 <BR>
Navneet Meena B21CS051

### _Data Preprocessing & Visualisation_
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import warnings
warnings.filterwarnings("ignore")
import seaborn as sns

data = pd.read_csv('./OnlineRetail.csv', encoding='unicode_escape')
data.head()

data.describe()

"""### Handling missing values
Customer ID column has a lot of missing values which are not useful for the purpose of clustering. These are therefore dropped
"""

data.isnull().sum()

data = data.dropna().reset_index(drop=True)
data["TotalPrice"] = data["Quantity"]*data["UnitPrice"]
data

"""### Country-wise contribution towards total revenue
Country wise revenue generation has been plotted using bar graph. United Kingdom has the most significant contribution.
"""

countrybase_retail = data.groupby(['Country']).agg(
    InvoiceCount = ('InvoiceNo', 'count'),
    QuantityCount = ('Quantity', 'count'),
    TotalPrice = ('TotalPrice', 'sum'),
    Customers = ('CustomerID', 'count')
).reset_index()
countrybase_retail.sort_values('TotalPrice', ascending=False, inplace=True, ignore_index=True)

sns.barplot(countrybase_retail.head(10), x = "Country", y = "TotalPrice", palette="cool")

"""###  Feature Selection & Engineering
Irrelevant features are dropped. Samples showing returned items (those having unitPrice or Qty  < 0) are dropped as they are not useful for the purpose of clustering. Total Price = Unit Price * Qty is added. Customer wise Total Price and Freqency is determined.
"""

data.drop(['StockCode', 'InvoiceDate','Description','Country'],axis = 1, inplace =True)

data = data[data["Quantity"] > 0] 
data = data[data['UnitPrice'] > 0]
data.describe()

Amt = data.groupby('CustomerID')['TotalPrice'].sum()
Amt = Amt.reset_index()
Amt.columns = ['CustomerID', 'Amount']

frq = data.groupby('CustomerID')['InvoiceNo'].count()
frq = frq.reset_index()
frq.columns = ['CustomerID', 'Frequency']

df1 = pd.merge(Amt, frq, on='CustomerID', how='inner')
df1.describe()

"""### Outlier Detection
Outlier Detection has been done using _Box Plot & Isolation Forest_.
"""

fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(6,6))
fig.suptitle('Outliers\n', size = 25)

sns.boxplot(ax=axes[0], data=df1['Amount'], palette='Spectral', color='red').set_title("Amount")
sns.boxplot(ax=axes[1], data=df1['Frequency'], palette='Spectral').set_title("Frequency")

plt.tight_layout()

from sklearn.ensemble import IsolationForest
df2 = df1.copy()

model=IsolationForest(n_estimators=150, max_samples='auto', contamination=float(0.1), max_features=1.0)
model.fit(df2)

scores=model.decision_function(df2)
anomaly=model.predict(df2)

df2['scores']=scores
df2['anomaly']=anomaly

anomaly = df2.loc[df2['anomaly']==-1]
anomaly_index = list(anomaly.index)
print('Total number of outliers is:', len(anomaly))

df2 = df2.drop(anomaly_index, axis = 0).reset_index(drop=True)

fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(6,6))
fig.suptitle('Outliers\n', size = 25)

sns.boxplot(ax=axes[0], data=df2['Amount'], color="#a2d2ff").set_title("Amount")
sns.boxplot(ax=axes[1], data=df2['Frequency'], color="#a2d2ff").set_title("Frequency")

plt.tight_layout()

"""### Standard Scaling
Scaling is necessary because the large range features might have undue influence on the cluster formation.
"""

df2.drop(['scores', 'anomaly'], axis = 1, inplace =True)

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
df3 = scaler.fit_transform(df2)

df3 = pd.DataFrame(df3, columns=df2.columns)

"""### Optimal Number of Clusters
Optimal number of clusters is found using <br>
* Elbow Method
* Silhouette Analysis <br>
##### __Optimal value of k = 5 or 6.__
"""

from sklearn.cluster import KMeans
wcss = []
for i in range(1, 10):
    model = KMeans(n_clusters=i, init='k-means++', random_state=42)
    model.fit(df3)
    wcss.append(model.inertia_)

plt.plot(range(1, 10), wcss)
plt.title("Elbow Method")
plt.xlabel("No. Clusters")
plt.ylabel("wcss")
plt.show()

from yellowbrick.cluster import SilhouetteVisualizer
fig, ax = plt.subplots(3, 2, figsize=(13,8))
fig.suptitle('Silhouette Analysis for 2-7 Clusters', size = 18)
plt.tight_layout()

for i in [2, 3, 4, 5, 6, 7]:
    km = KMeans(n_clusters=i, init='k-means++', n_init=10, max_iter=100, random_state=42)
    q, mod = divmod(i, 2)

    visualizer = SilhouetteVisualizer(km, colors='cool', ax=ax[q-1][mod])
    visualizer.fit(df3)

df = df3.drop(columns = "CustomerID", axis=1)

"""### KMeans """

from sklearn.cluster import KMeans
Kmean =KMeans(n_clusters=5)
Kmean.fit(df)
y_preds = Kmean.predict(df)

plt.scatter(df["Frequency"], df["Amount"], c=y_preds, s=40, cmap='cool', edgecolors='k', alpha=0.7, linewidths=1)

"""### Silhouette Score for KMeans"""

from sklearn import metrics
sse = metrics.silhouette_score(df, Kmean.labels_, metric="euclidean")
print("The SSE Score for KMeans model is {}".format(round(sse, 4)))

"""### Heirarchial Clustering"""

from sklearn.cluster import AgglomerativeClustering
model = AgglomerativeClustering(n_clusters=6, distance_threshold=None).fit(df)

plt.scatter(df["Frequency"], df["Amount"], c=model.labels_, s=40, cmap='cool', edgecolors='k', alpha=0.7, linewidths=1)

"""### Silhouette Score for Agglomerative Clustering"""

from sklearn import metrics
sse = metrics.silhouette_score(df, model.labels_, metric="euclidean")
print("The SSE Score for Agglomerative model is {}".format(round(sse, 4)))

"""### DBSCAN"""

from sklearn.cluster import DBSCAN
model_dbs = DBSCAN(eps = 0.2, min_samples = 50).fit(df)

plt.scatter(df["Frequency"], df["Amount"], c=model_dbs.labels_, s=40, cmap='cool', edgecolors='k', alpha=0.7, linewidths=1)

"""### Silhouette Score for DBSCAN"""

from sklearn import metrics
sse = metrics.silhouette_score(df, model_dbs.labels_, metric="euclidean")
print("The SSE Score for DBSCAN model is {}".format(round(sse, 4)))